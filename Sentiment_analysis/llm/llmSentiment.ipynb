{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e897fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Midterm-2'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../..')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8febbe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c8d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from src.llm import RotateGemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdcba92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/processsed/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc3c74e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5474, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b1b6fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 API keys\n"
     ]
    }
   ],
   "source": [
    "llm = RotateGemini(model_name = 'gemini-2.0-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e42f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_id', 'author_id', 'rating', 'is_recommended', 'helpfulness',\n",
       "       'total_feedback_count', 'total_neg_feedback_count',\n",
       "       'total_pos_feedback_count', 'submission_time', 'review_text',\n",
       "       'review_title', 'skin_tone', 'eye_color', 'skin_type', 'hair_color',\n",
       "       'product_id', 'product_name', 'brand_name', 'price_usd', 'sentiment',\n",
       "       'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872efdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[['review_id','sentiment']]\n",
    "data['sentiment'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e97cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import re\n",
    "from typing import List, Optional, Tuple, Dict, Any\n",
    "\n",
    "def _strip_fences(s: str) -> str:\n",
    "    \"\"\"Remove code fences and JSON markers from LLM output.\"\"\"\n",
    "    text = s.strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        lines = s.splitlines()\n",
    "        # Remove first fence line\n",
    "        if lines[0].startswith(\"```\"):\n",
    "            lines = lines[1:]\n",
    "        # Remove last fence line\n",
    "        if lines and lines[-1].startswith(\"```\"):\n",
    "            lines = lines[:-1]\n",
    "        s = \"\\n\".join(lines)\n",
    "    # If \"json\" marker remains at the beginning\n",
    "    if s.strip().lower().startswith(\"json\"):\n",
    "        s = re.sub(r\"^json\\s*\", \"\", s, flags=re.IGNORECASE)\n",
    "    return s.strip()\n",
    "\n",
    "def get_sentiments_with_ids(id_texts: List[Tuple[str, Optional[Any]]], llm_function) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Process a batch of text-id pairs and return sentiment classifications with IDs.\n",
    "    \n",
    "    Args:\n",
    "        id_texts: List of (id, text) tuples to analyze\n",
    "        llm_function: Function that accepts a prompt and returns LLM response\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries with id and sentiment (0=negative, 1=neutral, 2=positive, None=empty)\n",
    "    \"\"\"\n",
    "    items = []\n",
    "    for _id, text in id_texts:\n",
    "        # Convert text to string if it's not None (handles float, int, etc.)\n",
    "        if text is None:\n",
    "            items.append(f\"{_id}: <EMPTY>\")\n",
    "        else:\n",
    "            # Convert to string before calling strip()\n",
    "            text_str = str(text)\n",
    "            if not text_str.strip():\n",
    "                items.append(f\"{_id}: <EMPTY>\")\n",
    "            else:\n",
    "                items.append(f\"{_id}: {text_str.strip()}\")\n",
    "    \n",
    "    joined_items = \"\\n\".join(items)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Below are {len(id_texts)} review texts, each with a unique ID. Empty reviews are marked as <EMPTY>.\n",
    "Extract the sentiment for each and return a valid JSON array of objects, each with two keys:\n",
    "- \"id\": string (same as input ID)\n",
    "- \"sentiment\": int. Only 0,1,2 with 0 is negative, 1 is neutral, 2 is postive.\n",
    "\n",
    "IMPORTANT:\n",
    "- For <EMPTY> reviews, return sentiment = null.\n",
    "- Return ONLY a valid JSON array. No extra text, no markdown, no comments.\n",
    "\n",
    "List of reviews:\n",
    "{joined_items}\n",
    "\"\"\".strip()\n",
    "\n",
    "    # Call LLM\n",
    "    resp = llm_function(prompt)\n",
    "    raw = _strip_fences(resp)\n",
    "    raw = re.sub(r\",\\s*([\\]\\}])\", r\"\\1\", raw)\n",
    "\n",
    "    try:\n",
    "        arr = json.loads(raw)\n",
    "        if not isinstance(arr, list):\n",
    "            raise ValueError(\"Result is not a list.\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise RuntimeError(f\"Could not parse JSON:\\n{raw}\") from e\n",
    "\n",
    "    # Normalize null values\n",
    "    def norm_sent(x):\n",
    "        if x is None: return None\n",
    "        x = str(x).strip().lower()\n",
    "        return None if x in (\"\", \"null\", \"none\") else x\n",
    "\n",
    "    results = [{\"id\": str(d[\"id\"]), \"sentiment\": norm_sent(d.get(\"sentiment\"))} for d in arr if \"id\" in d]\n",
    "    return results\n",
    "\n",
    "def analyze_sentiment_batch(data: pd.DataFrame,\n",
    "                            llm_function,\n",
    "                            chunk_size: int = 100,\n",
    "                            text_column: str = 'review_text',\n",
    "                            id_column: str = 'review_id',\n",
    "                            sentiment_column: str = 'sentiment',\n",
    "                            output_file_prefix: str = 'sentiment_results',\n",
    "                            save_each_batch: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process a DataFrame with reviews in batches and add sentiment classifications.\n",
    "    Saves intermediate results after each batch for safety.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame containing text to analyze\n",
    "        llm_function: Function that accepts a prompt and returns LLM response\n",
    "        chunk_size: Number of texts to process in each batch\n",
    "        text_column: Column name containing the text to analyze\n",
    "        id_column: Column name containing text IDs\n",
    "        sentiment_column: Column name to store sentiment results\n",
    "        output_file_prefix: Prefix for output files\n",
    "        save_each_batch: Whether to save intermediate results after each batch\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added sentiment column\n",
    "    \"\"\"\n",
    "    result_data = data.copy()\n",
    "    \n",
    "    # Initialize sentiment column if it doesn't exist\n",
    "    if sentiment_column not in result_data.columns:\n",
    "        result_data[sentiment_column] = None\n",
    "    \n",
    "    batch_number = 0\n",
    "    \n",
    "    # Process in batches\n",
    "    for start in range(0, len(result_data), chunk_size):\n",
    "        batch_number += 1\n",
    "        end = min(start + chunk_size, len(result_data))\n",
    "        chunk = result_data.iloc[start:end]\n",
    "        id_text_pairs = list(zip(chunk[id_column].astype(str), chunk[text_column]))\n",
    "        \n",
    "        try:\n",
    "            results = get_sentiments_with_ids(id_text_pairs, llm_function)\n",
    "            \n",
    "            # Update the main dataframe with results\n",
    "            for res in results:\n",
    "                result_data.loc[result_data[id_column].astype(str) == res[\"id\"], sentiment_column] = res[\"sentiment\"]\n",
    "            \n",
    "            # Print progress info\n",
    "            print(f\"Processed batch {batch_number}: {start}-{end}/{len(result_data)} samples\")\n",
    "            \n",
    "            # Save intermediate results for this batch\n",
    "            if save_each_batch:\n",
    "                # Save just this batch's results\n",
    "                batch_filename = f\"data/result/llm/{output_file_prefix}_batch_{batch_number}.csv\"\n",
    "                batch_df = pd.DataFrame(results)\n",
    "                batch_df.to_csv(batch_filename, index=False)\n",
    "                print(f\"Saved batch results to {batch_filename}\")\n",
    "                \n",
    "                # Also save current progress of the full dataset\n",
    "                progress_filename = f\"ddata/result/llm/{output_file_prefix}_progress.csv\"\n",
    "                result_data.to_csv(progress_filename, index=False)\n",
    "                print(f\"Updated progress saved to {progress_filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error in batch {batch_number} (rows {start}-{end}): {str(e)}\"\n",
    "            print(error_msg)\n",
    "            \n",
    "            # Save error information\n",
    "            if save_each_batch:\n",
    "                error_file = f\"{output_file_prefix}_error_batch_{batch_number}.txt\"\n",
    "                with open(error_file, 'w') as f:\n",
    "                    f.write(error_msg)\n",
    "                print(f\"Error details saved to {error_file}\")\n",
    "    \n",
    "    # Save final complete results\n",
    "    final_filename = f\"data/result/llm/{output_file_prefix}_complete.csv\"\n",
    "    result_data.to_csv(final_filename, index=False)\n",
    "    print(f\"Complete results saved to {final_filename}\")\n",
    "    \n",
    "    return result_data\n",
    "\n",
    "# Example usage:\n",
    "# Define a function to call your LLM\n",
    "def llm_function(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Call the language model with the given prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The text prompt to send to the LLM\n",
    "        \n",
    "    Returns:\n",
    "        The LLM's response as a string\n",
    "    \"\"\"\n",
    "    message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    return llm(message)  # You need to define or integrate the `llm()` function\n",
    "\n",
    "\n",
    "# # Process a batch of data\n",
    "# result_df = analyze_sentiment_batch(\n",
    "#     data,  # Process first 100 rows\n",
    "#     llm_function=llm_function,\n",
    "#     chunk_size=250\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa97e96b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "28bf90b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5474, 2)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6ef35667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "author_id",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "rating",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "is_recommended",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "helpfulness",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "total_feedback_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_neg_feedback_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "total_pos_feedback_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "submission_time",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "review_title",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "skin_tone",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "eye_color",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "skin_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "hair_color",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "product_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "brand_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "price_usd",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "sentiment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "97abee4d-9adf-4da6-af71-014b6750f556",
       "rows": [
        [
         "231",
         "122760",
         null,
         "5",
         "1.0",
         "1.0",
         "0",
         "0",
         "0",
         "2022-08-22",
         null,
         null,
         "light",
         "hazel",
         "combination",
         "brown",
         "P423688",
         "Daily Microfoliant Exfoliator",
         "Dermalogica",
         "65.0",
         null,
         "2022-08-22"
        ],
        [
         "667",
         "746432",
         null,
         "5",
         "1.0",
         "1.0",
         "0",
         "0",
         "0",
         "2022-09-02",
         null,
         null,
         "lightMedium",
         "brown",
         "combination",
         "brown",
         "P501760",
         "Guava Vitamin C Bright-Eye Gel Cream",
         "Glow Recipe",
         "38.0",
         null,
         "2022-09-02"
        ],
        [
         "1235",
         "1014797",
         null,
         "5",
         "1.0",
         "1.0",
         "2",
         "0",
         "2",
         "2022-09-23",
         null,
         null,
         "fairLight",
         "hazel",
         "dry",
         "brown",
         "P500894",
         "Fat Water Hydrating Milky Toner Essence with Hyaluronic Acid + Tamarind",
         "Fenty Skin",
         "34.0",
         null,
         "2022-09-23"
        ]
       ],
       "shape": {
        "columns": 21,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>is_recommended</th>\n",
       "      <th>helpfulness</th>\n",
       "      <th>total_feedback_count</th>\n",
       "      <th>total_neg_feedback_count</th>\n",
       "      <th>total_pos_feedback_count</th>\n",
       "      <th>submission_time</th>\n",
       "      <th>review_text</th>\n",
       "      <th>...</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>skin_type</th>\n",
       "      <th>hair_color</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price_usd</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>122760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-08-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>light</td>\n",
       "      <td>hazel</td>\n",
       "      <td>combination</td>\n",
       "      <td>brown</td>\n",
       "      <td>P423688</td>\n",
       "      <td>Daily Microfoliant Exfoliator</td>\n",
       "      <td>Dermalogica</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>746432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>lightMedium</td>\n",
       "      <td>brown</td>\n",
       "      <td>combination</td>\n",
       "      <td>brown</td>\n",
       "      <td>P501760</td>\n",
       "      <td>Guava Vitamin C Bright-Eye Gel Cream</td>\n",
       "      <td>Glow Recipe</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>1014797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>fairLight</td>\n",
       "      <td>hazel</td>\n",
       "      <td>dry</td>\n",
       "      <td>brown</td>\n",
       "      <td>P500894</td>\n",
       "      <td>Fat Water Hydrating Milky Toner Essence with H...</td>\n",
       "      <td>Fenty Skin</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-09-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      review_id author_id  rating  is_recommended  helpfulness  \\\n",
       "231      122760       NaN       5             1.0          1.0   \n",
       "667      746432       NaN       5             1.0          1.0   \n",
       "1235    1014797       NaN       5             1.0          1.0   \n",
       "\n",
       "      total_feedback_count  total_neg_feedback_count  \\\n",
       "231                      0                         0   \n",
       "667                      0                         0   \n",
       "1235                     2                         0   \n",
       "\n",
       "      total_pos_feedback_count submission_time review_text  ...    skin_tone  \\\n",
       "231                          0      2022-08-22         NaN  ...        light   \n",
       "667                          0      2022-09-02         NaN  ...  lightMedium   \n",
       "1235                         2      2022-09-23         NaN  ...    fairLight   \n",
       "\n",
       "     eye_color    skin_type hair_color product_id  \\\n",
       "231      hazel  combination      brown    P423688   \n",
       "667      brown  combination      brown    P501760   \n",
       "1235     hazel          dry      brown    P500894   \n",
       "\n",
       "                                           product_name   brand_name  \\\n",
       "231                       Daily Microfoliant Exfoliator  Dermalogica   \n",
       "667                Guava Vitamin C Bright-Eye Gel Cream  Glow Recipe   \n",
       "1235  Fat Water Hydrating Milky Toner Essence with H...   Fenty Skin   \n",
       "\n",
       "     price_usd  sentiment        date  \n",
       "231       65.0        NaN  2022-08-22  \n",
       "667       38.0        NaN  2022-09-02  \n",
       "1235      34.0        NaN  2022-09-23  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['author_id'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8be7d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "def aggregate_from_pattern(pattern, file_type=\"csv\", add_source_column=False):\n",
    "    matched_files = glob.glob(pattern)\n",
    "    df_list = []\n",
    "\n",
    "    for file in matched_files:\n",
    "        try:\n",
    "            if file_type == \"csv\":\n",
    "                df = pd.read_csv(file)\n",
    "            elif file_type == \"json\":\n",
    "                df = pd.read_json(file)\n",
    "            elif file_type == \"parquet\":\n",
    "                df = pd.read_parquet(file)\n",
    "            else:\n",
    "                print(f\"Không hỗ trợ định dạng {file_type}\")\n",
    "                continue\n",
    "            \n",
    "            if add_source_column:\n",
    "                df['source_file'] = file\n",
    "            df_list.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi khi đọc {file}: {e}\")\n",
    "    \n",
    "    if df_list:\n",
    "        combined_df = pd.concat(df_list, ignore_index=True)\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"Không tìm thấy file phù hợp.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Ví dụ sử dụng:\n",
    "combined_df = aggregate_from_pattern(\"data/result/llm/sentiment_results_batch_*.csv\", file_type=\"csv\", add_source_column=True)\n",
    "# combined_df.to_csv(\"combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b16271b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.sort_values(by='review_id')\n",
    "combined_df = combined_df.sort_values(by='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "05d5b7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.fillna(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a4fb93f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy           : 0.8679\n",
      "F1 Score (macro)   : 0.5357\n",
      "F1 Score (weighted): 0.8853\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 495   31    0    0]\n",
      " [ 163  222   25    0]\n",
      " [  39  462 4034    3]\n",
      " [   0    0    0    0]] \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7102    0.9411    0.8095       526\n",
      "         1.0     0.3105    0.5415    0.3947       410\n",
      "         2.0     0.9938    0.8889    0.9385      4538\n",
      "         4.0     0.0000    0.0000    0.0000         0\n",
      "\n",
      "    accuracy                         0.8679      5474\n",
      "   macro avg     0.5036    0.5929    0.5357      5474\n",
      "weighted avg     0.9154    0.8679    0.8853      5474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "y_true = target['sentiment']\n",
    "y_pred = combined_df['sentiment']\n",
    "\n",
    "# 1. Accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 2. F1 Score\n",
    "f1_macro    = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
    "f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# 3. Confusion Matrix\n",
    "conf_mtx = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 4. Classification Report (với zero_division để không bị lỗi chia 0)\n",
    "class_report = classification_report(\n",
    "    y_true, y_pred,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    ")\n",
    "\n",
    "# In kết quả\n",
    "print(f\"Accuracy           : {accuracy:.4f}\")\n",
    "print(f\"F1 Score (macro)   : {f1_macro:.4f}\")\n",
    "print(f\"F1 Score (weighted): {f1_weighted:.4f}\\n\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_mtx, \"\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
